{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29066e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import mutual_info_regression, mutual_info_classif\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "tf.compat.v1.random.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import Model, predict_next_day, forecast, stock_price_preprocessing\n",
    "from Pre import generate_benchmark_data, calculate_excess_return, discretize_features, cfs, generate_composite_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78607581",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_file_path = \"./000001.SZ.csv\"\n",
    "\n",
    "stock_data = pd.read_csv(stock_file_path)\n",
    "\n",
    "stock_data = generate_benchmark_data(stock_data)\n",
    "\n",
    "stock_data = calculate_excess_return(stock_data)\n",
    "\n",
    "stock_data = generate_composite_index(stock_data)\n",
    "\n",
    "target_column = 'excess_return'  \n",
    "    \n",
    "feature_columns = stock_data.columns.tolist()\n",
    "\n",
    "feature_columns.remove(target_column)\n",
    "\n",
    "stock_data = discretize_features(stock_data, feature_columns)\n",
    "\n",
    "selected_features = cfs(stock_data, target_column)\n",
    "\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e05b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_folder_path = \".\\stock data\"\n",
    "other_folder_path = \".\\CG2408_PHASE2\"\n",
    "other_other_folder_path = \".\\CG2408_PHASE3\"\n",
    "\n",
    "csv_files = [f for f in os.listdir(file_folder_path) if f.endswith('.csv')]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(file_folder_path, csv_file)\n",
    "    other_data_file = os.path.join(other_folder_path, csv_file)\n",
    "    other_other_data_file = os.path.join(other_other_folder_path, csv_file)\n",
    "    \n",
    "    file_name_without_extension = os.path.splitext(csv_file)[0]\n",
    "\n",
    "    data = pd.read_csv(file_path)\n",
    "    other_data = pd.read_csv(other_data_file)\n",
    "    other_other_data =  pd.read_csv(other_other_data_file)\n",
    "\n",
    "    merged_data = pd.concat([other_data,data], axis=0).reset_index(drop=True)\n",
    "\n",
    "    merged_data = generate_composite_index(merged_data)\n",
    "    \n",
    "    threshold = 0.1\n",
    "    \n",
    "    merged_data['price_change'] = merged_data['close'].pct_change()\n",
    "\n",
    "    alerts = merged_data[abs(merged_data['price_change']) > threshold]\n",
    "\n",
    "\n",
    "    first_alert_date = 1000\n",
    "    if not alerts.empty:\n",
    "        if alerts.index[0]>1000:\n",
    "            pass\n",
    "        elif alerts.index[0]<250:\n",
    "            first_alert_date=250 \n",
    "        else:\n",
    "            first_alert_date = alerts.index[0]\n",
    "    merged_data = merged_data[merged_data.index <= first_alert_date]\n",
    "    \n",
    "    merged_data = pd.concat([other_data, merged_data])\n",
    "\n",
    "    merged_data = merged_data.drop_duplicates()\n",
    "\n",
    "    merged_data = merged_data.reset_index(drop=True)\n",
    "\n",
    "    merged_data= merged_data.iloc[::-1][selected_columns]\n",
    "\n",
    "    X, y = stock_price_preprocessing(merged_data, 1, 1, selected_columns)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.1)\n",
    "\n",
    "    num_samples = len(X_train)\n",
    "\n",
    "    num_layers = 1\n",
    "    size_layer = 128\n",
    "    size = X.shape[2]\n",
    "    timestamp = 5\n",
    "    epoch = 300\n",
    "    dropout_rate = 0.8\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 64\n",
    "\n",
    "    modelnn, y_test, y_pred = forecast(X_train, y_train, X_test, y_test, learning_rate, \n",
    "                                       num_layers, size, size_layer, dropout_rate, \n",
    "                                       epoch, batch_size)\n",
    "\n",
    "    historical_data = X[-1][0]\n",
    "    next_day_price = predict_next_day(modelnn, historical_data)\n",
    "    close_value = merged_data['close'].iloc[-1]\n",
    "    relative_change = (next_day_price - close_value) / close_value\n",
    "    print(f\"Relative change for {csv_file}: {relative_change}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
